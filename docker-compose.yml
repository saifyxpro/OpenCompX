version: '3.8'

services:
  backend:
    build:
      context: ./backend
      dockerfile: ../docker/backend.Dockerfile
    container_name: openmanus-backend
    ports:
      - "8000:8000"
    environment:
      - HOST=0.0.0.0
      - PORT=8000
    env_file:
      - ./backend/.env
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock # Required for spawning agents
      - ./backend:/app # Hot reload for dev, or persistence
    restart: unless-stopped

  frontend:
    build:
      context: ./frontend
      dockerfile: ../docker/frontend.Dockerfile
    container_name: openmanus-frontend
    ports:
      - "3000:3000"
    environment:
      - HOST=0.0.0.0
      - PORT=3000
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - BACKEND_URL=http://backend:8000
    depends_on:
      - backend
    restart: unless-stopped

# Note: We assume vLLM is running on the host or another machine, 
# as it requires GPU passthrough which is complex in standard compose.
